Main Header: Evaluation

To reiterate, the goal of this project is to evaluate how well we can
classify the current state of a device (what applications are currently open),
and what applications are being opened. Furthermore, we want to do so under
two scenarios, one in which we have access to the device (we have application
level data such as which applications are currently open) and one in which we
do not have access to the device. To do so, we first parsed through the CPU
trace files from our experiments and used the generated training and testing
files to train decision tree based classification models.

Sub Header: Data Parsing

In order to make our classification models as close to real life as possible, we
used only the features that would be available if we had actually remotely
sensed the CPU usage. The features that we used for our models only involved
aggregate CPU data and application level data. Features that involved reads,
writes, and networking data were removed. It is important to note that
networking data is easy to obtain and would make our models much more
accurate. Additionally, features that involved individual core data was
removed. Using the individual CPU data we were able to find aggregate CPU data
which is a much more realistic feature to use. We ultimately ended up with
200 data points for experiment one and 800 data points for experiment 2.

To create the data to train our models, we found the points that an application
was opened and cut a part of that trace file out. One second was used
before that point and eight seconds were used after that point. Additionally,
a nine second interval was captured after the application had been opened
for three seconds. This was done to include CPU trace data on time periods
where we know that no applications were being opened and thus the state of the
device must remain the same.

Beyond the aggregate CPU time-series data that we had extracted from the larger
trace files. We also computed the derivative of this time-series in order to
capture features related to the speed at which CPU usage changed as it is
possible that different CPU applications take over CPU usage at different
speeds.

Sub Header: Classification Models

For the two experiments that we conducted we will first discuss the binary
classification results, next we will discuss the application level
classification results, and finally we will finish with a discussion on the
device state classification results.

To begin, the area that we evaluated was whether or not we would be able to take CPU
traces and classify whether or not an application was opened, a binary problem.
For the binary classification, we chose to go with support vector machine,
logistic regression, and random forest models. The support vector model and
logistic regression model were chosen due to their affinity towards solving
binary problems. The random forest was included later after observing the
models performance on the other classification tasks. To preface the results
of our models, a dummy classifier was trained as well to see how well our models
perform as compared to a model that learned nothing. The accuracy of this model
was 42%.

For experiment one, we observed that the random forest model produced
the best results in both scenarios. Even without the application level data
the model was able to classify with a 93% accuracy, with the application level
data the accuracy improved to 95%. For experiment two, the random forest and
logistic regression models both produced similar results with and without the
application level data. The random forest model had an 84% accuracy with
application data and an 81% accuracy without application data when using a
logistic regression model. When looking at the confusion matrix we observe
that most of the wrong classifications are classifying turning on an
application as no changes happening. It is possible that when many applications
are open together it becomes difficult to distinguish between an idle state and
a fully utilized state. If we look at the feature importance graph the top
feature is CPU variance, the variance of these two states is probably very
similar when the CPU is running at high capacity.

For our next classification problem, we used the same data from the binary
classification but with the goal of classifying which application was opened.
Initially we expected to see the accuracy of our model decrease but surprisingly
we found that the accuracy of the models were actually quite similar to that of
the binary classification. For the application classification models we used
three different tree based models; random forest, adaboost, and gradient
boost. Across both experiments, with and without application state data,
random forest generally performed the best out of all of them. With the state
data, random forest was able to achieve 93% accuracy on experiment one and
86% accuracy with experiment two. Around 300 decision trees were built to
help classify the application being opened. When we did not include the state
data as a feature, the results from the random forest classifier were around
the same for experiment one, 95% accuracy, but significantly worse for
experiment two where the start states varied widely, the accuracy was 68%.
We believe that this comes from the fact that some of the apps open with a
similar CPU trace.

One interesting observation from the binary and application classification
models is that with the state data for experiment two, the two problems
actually have very similar accuracy scores (84% and 86% respectively).
Intuitively we would expect to see that the score go down but when we look at
the confusion matrix we can see that almost all of the incorrect classifications
are misclassified as no activity occurring which is why the two problems
produce similar performance scores.

The most difficult classification problem is that of classifying the state of
the device using only the CPU trace data. This would be incredibly useful in a
situation where we do not have access to an IoT device and would like to know
exactly what the device is doing. For this problem we are only allowed to use
the CPU data. Again we use the same models that we used to solve the previous
two problems, the results were the best for the random forest model with an
accuracy of 58%. This accuracy is understandably worse than the previous
classification problems but is not a bad result considering all features
were removed, even the granularity of individual CPU core usage, and only
aggregate CPU usage was used. This classification could perhaps be improved
by using a model that takes in the time series as input.

An interesting question to pose next is if it is possible that opening up an
application has a different CPU trace change depending on the current state of
the device. For example, if we open a video recording application while two
other applications are also running or if we open a video recording application
while four other applications are also running, will we see a difference in
how CPU changes? This could be a possible scenario if we have access to an IoT
device and would like to know exactly what is running on our device. When we
ran the models and included the application opening data we observed that
random forest model improved to 73% accuracy which seems to suggest there is
some difference in CPU change depending on the current state of the device.
